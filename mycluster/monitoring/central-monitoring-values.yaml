# Central Prometheus + Grafana Helm values
prometheus:
  prometheusSpec:
    serviceMonitorSelectorNilUsesHelmValues: false
    serviceMonitorSelector: {}
    podMonitorSelector: {}
    ruleSelector: {}
    serviceAccountName: prometheus

    # Federation scrape jobs (update targets for your clusters)
    additionalScrapeConfigs:
      - job_name: 'cluster1-prometheus'
        honor_labels: true
        metrics_path: '/federate'
        params:
          'match[]': ['{__name__=~".+"}']
        static_configs:
          - targets:
              [
                'central-monitoring-kube-pr-prometheus.monitoring.svc.cluster.local:9090',
              ]

  server:
    persistence:
      enabled: true
      size: 5Gi
      storageClassName: local-storage
      # existingClaim: prometheus-pvc

    service:
      type: ClusterIP

  ingress:
    enabled: true
    ingressClassName: traefik
    hosts:
      - prometheus.example.test
    annotations:
      cert-manager.io/cluster-issuer: my-ca-issuer
    tls:
      - secretName: prometheus-tls
        hosts:
          - prometheus.example.test

alertmanager:
  ingress:
    enabled: true
    ingressClassName: traefik
    hosts:
      - alertmanager.example.test
    annotations:
      cert-manager.io/cluster-issuer: my-ca-issuer
    tls:
      - secretName: alertmanager-tls
        hosts:
          - alertmanager.example.test

  alertmanagerSpec:
    replicas: 1
    externalUrl: 'https://alertmanager.example.test'

    # Alertmanager configuration
    config:
      global:
        resolve_timeout: 5m
      route:
        receiver: 'team-slack'
        group_by: ['alertname', 'namespace']
        group_wait: 30s
        group_interval: 5m
        repeat_interval: 1h
      receivers:
        - name: 'team-slack'
          slack_configs:
            - api_url: 'https://hooks.slack.com/services/XXXX/YYYY/ZZZZ'
              channel: '#alerts'

grafana:
  adminUser: admin
  adminPassword: 'ChangeMe123'

  ingress:
    enabled: true
    ingressClassName: traefik
    hosts:
      - grafana.example.test
    annotations:
      cert-manager.io/cluster-issuer: my-ca-issuer
    tls:
      - secretName: grafana-tls
        hosts:
          - grafana.example.test

  service:
    type: ClusterIP

  persistence:
    enabled: true
    size: 5Gi
    storageClassName: local-storage
    existingClaim: grafana-pvc

  datasources:
    datasource.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          type: prometheus
          access: proxy
          url: http://central-monitoring-kube-pr-prometheus.monitoring:9090/
          isDefault: true

        - name: Alertmanager
          type: alertmanager
          access: proxy
          url: http://central-monitoring-kube-pr-alertmanager.monitoring:9093/
          jsonData:
            implementation: prometheus

  # alerting:
  #   alertmanager:
  #     - name: central-monitoring
  #       datasource: Prometheus
  #       url: http://central-monitoring-kube-pr-alertmanager.monitoring:9093

prometheusRules:
  groups:
    - name: node-alerts
      rules:
        - alert: NodeNotReady
          expr: kube_node_status_condition{condition="Ready",status="false"} == 1
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: 'Node {{ $labels.node }} in {{ $labels.cluster }} is NotReady'
            description: 'Node {{ $labels.node }} in cluster {{ $labels.cluster }} has been NotReady for more than 5 minutes.'

        - alert: HighCPUUsage
          expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100) > 90
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: 'High CPU usage on {{ $labels.instance }}'
            description: 'CPU usage > 90% for more than 5 minutes.'

        - alert: HighMemoryUsage
          expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 90
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: 'High memory usage on {{ $labels.instance }}'
            description: 'Memory usage > 90% for more than 5 minutes.'
